# ðŸ“Œ Import Libraries
import os
import gspread
import pandas as pd
import nest_asyncio
import asyncio
import re
from googlesearch import search

from oauth2client.service_account import ServiceAccountCredentials
from langchain.docstore.document import Document
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory

from telegram import Update
from telegram.ext import ApplicationBuilder, ContextTypes, MessageHandler, filters

# =====================
# ðŸ“Œ Google Sheet Setup
# =====================
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
creds = ServiceAccountCredentials.from_json_keyfile_name("credentials.json", scope)
client = gspread.authorize(creds)
sheet = client.open("Imdad Building Bot").sheet1
data = sheet.get_all_records()
df = pd.DataFrame(data)

# =====================
# ðŸ“Œ Vector Store Setup
# =====================
documents = []
for _, row in df.iterrows():
    content = f"Item: {row['Item']} | Rate: {row['Rate']} {row['Unit']} | Remarks: {row['Remarks']}"
    documents.append(Document(page_content=content))

embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
db = FAISS.from_documents(documents, embedding)
retriever = db.as_retriever()

# =========================
# ðŸ“Œ LLM + Memory + Chain
# =========================
os.environ["OPENAI_API_KEY"] = "Write your own api"
os.environ["OPENAI_API_BASE"] = "https://openrouter.ai/api/v1"

llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.4)
memory = ConversationBuffera = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

qa_chain = ConversationalRetrievalChain.from_llm(
    llm=llm,
    retriever=retriever,
    memory=memory,
    return_source_documents=False
)

# =====================
# ðŸ“Œ Helper Functions
# =====================
def is_bill_query(query):
    """Check if the query is about calculating a bill."""
    return "bill" in query.lower() and ("bori" in query.lower() or "bag" in query.lower() or "sack" in query.lower())

def calculate_bill(query, context):
    """Calculate bill based on quantity and item rate from context."""
    match = re.search(r'(\d+)\s*(bag|bori|sack)', query.lower())
    if not match:
        return None, "Please specify the quantity of cement bags (e.g., '15 bori')."

    quantity = int(match.group(1))
    prev_messages = memory.chat_memory.messages
    cement_rate = None

    for msg in prev_messages:
        if "cement" in msg.content.lower() and "rate" in msg.content.lower():
            rate_match = re.search(r'(\d+)\s*(per|bag|bori)', msg.content.lower())
            if rate_match:
                cement_rate = int(rate_match.group(1))
                break

    if not cement_rate:
        return None, "Please ask for the cement rate first (e.g., 'What is the cement rate?')."

    total = quantity * cement_rate
    return total, f"Bill for {quantity} bags of cement at {cement_rate} per bag: {total}. Please provide your address to send the bill."

async def perform_web_search(query):
    """Perform a web search for general queries."""
    try:
        results = []
        for result in search(query, num_results=3):
            results.append(result)
        if results:
            return f"Here's what I found: {', '.join(results)}"
        return "Sorry, I couldn't find any relevant information."
    except Exception:
        return "Sorry, I couldn't perform the search right now."

# =====================
# ðŸ“Œ Telegram Bot Setup
# =====================
nest_asyncio.apply()
TELEGRAM_BOT_TOKEN = "write your own token"  # ðŸŸ¢ Your Telegram Bot Token

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_input = update.message.text.lower()

    # Handle bill calculation
    if is_bill_query(user_input):
        total, response = calculate_bill(user_input, context)
        if total:
            memory.save_context(
                {"question": user_input},
                {"answer": response, "bill_total": total, "awaiting_address": True}
            )
        await update.message.reply_text(response)
        return

    # Handle address input after bill calculation
    prev_messages = memory.chat_memory.messages
    if any("awaiting_address" in msg.additional_kwargs for msg in prev_messages):
        for msg in prev_messages:
            if "awaiting_address" in msg.additional_kwargs:
                bill_total = msg.additional_kwargs.get("bill_total")
                await update.message.reply_text(
                    f"Bill of {bill_total} has been sent to {user_input}. Thank you!"
                )
                memory.save_context(
                    {"question": user_input},
                    {"answer": "Address received.", "awaiting_address": False}
                )
                return

    # Handle building material queries using vector store
    if any(keyword in user_input for keyword in ["cement", "brick", "sand", "steel", "rate", "price", "material"]):
        response = qa_chain({"question": user_input})["answer"]
        await update.message.reply_text(response)
        return

    # Handle general conversation with web search
    response = await perform_web_search(user_input)
    await update.message.reply_text(response)

app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()
app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

async def main():
    print("ðŸ¤– Imdad GPT is now active on Telegram...")
    await app.run_polling()

# =====================
# ðŸ“Œ Start the Bot
# =====================
asyncio.run(main())
